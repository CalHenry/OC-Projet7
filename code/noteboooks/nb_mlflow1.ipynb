{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P7 - Prep the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction Cleaning Finale\n",
    "def cleaning(features, test_features, encoding=\"ohe\"):\n",
    "    \"\"\"Fonction cleaning finale\"\"\"\n",
    "    # Extract the ids\n",
    "    train_ids = features[\"SK_ID_CURR\"]\n",
    "    test_ids = test_features[\"SK_ID_CURR\"]\n",
    "\n",
    "    # Extract the labels for training\n",
    "    labels = features[\"TARGET\"]\n",
    "\n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns=[\"SK_ID_CURR\", \"TARGET\"])\n",
    "    test_features = test_features.drop(columns=[\"SK_ID_CURR\"])\n",
    "\n",
    "    # One Hot Encoding\n",
    "    if encoding == \"ohe\":\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "\n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join=\"inner\", axis=1)\n",
    "\n",
    "        # No categorical indices to record\n",
    "        cat_indices = \"auto\"\n",
    "\n",
    "    # Integer label encoding\n",
    "    elif encoding == \"le\":\n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "\n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == \"object\":\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(\n",
    "                    np.array(features[col].astype(str)).reshape((-1,))\n",
    "                )\n",
    "                test_features[col] = label_encoder.transform(\n",
    "                    np.array(test_features[col].astype(str)).reshape((-1,))\n",
    "                )\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "\n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "\n",
    "    print(\"Training Data Shape: \", features.shape)\n",
    "    print(\"Testing Data Shape: \", test_features.shape)\n",
    "\n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Impute the domainnomial features\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    features = imputer.fit_transform(features)\n",
    "    test_features = imputer.transform(test_features)\n",
    "\n",
    "    # Scale the domainnomial features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    features = scaler.fit_transform(features)\n",
    "    test_features = scaler.transform(test_features)\n",
    "\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    return feature_names, labels, features, test_features, train_ids, test_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n",
      "Testing data shape:  (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv(\"../../data/raw/application_train.csv\")\n",
    "print(\"Training data shape: \", app_train.shape)\n",
    "app_train.head(2)\n",
    "\n",
    "# Testing data features\n",
    "app_test = pd.read_csv(\"../../data/raw/application_test.csv\")\n",
    "print(\"Testing data shape: \", app_test.shape)\n",
    "app_test.head(2)\n",
    "\n",
    "# copy to add fe\n",
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()\n",
    "\n",
    "# feature engineering with domain knowledge variables\n",
    "app_train_domain[\"CREDIT_INCOME_PERCENT\"] = (\n",
    "    app_train_domain[\"AMT_CREDIT\"] / app_train_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_train_domain[\"ANNUITY_INCOME_PERCENT\"] = (\n",
    "    app_train_domain[\"AMT_ANNUITY\"] / app_train_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_train_domain[\"CREDIT_TERM\"] = (\n",
    "    app_train_domain[\"AMT_ANNUITY\"] / app_train_domain[\"AMT_CREDIT\"]\n",
    ")\n",
    "app_train_domain[\"DAYS_EMPLOYED_PERCENT\"] = (\n",
    "    app_train_domain[\"DAYS_EMPLOYED\"] / app_train_domain[\"DAYS_BIRTH\"]\n",
    ")\n",
    "\n",
    "app_test_domain[\"CREDIT_INCOME_PERCENT\"] = (\n",
    "    app_test_domain[\"AMT_CREDIT\"] / app_test_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_test_domain[\"ANNUITY_INCOME_PERCENT\"] = (\n",
    "    app_test_domain[\"AMT_ANNUITY\"] / app_test_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_test_domain[\"CREDIT_TERM\"] = (\n",
    "    app_test_domain[\"AMT_ANNUITY\"] / app_test_domain[\"AMT_CREDIT\"]\n",
    ")\n",
    "app_test_domain[\"DAYS_EMPLOYED_PERCENT\"] = (\n",
    "    app_test_domain[\"DAYS_EMPLOYED\"] / app_test_domain[\"DAYS_BIRTH\"]\n",
    ")\n",
    "\n",
    "# Create an anomalous flag column\n",
    "app_train_domain[\"DAYS_EMPLOYED_ANOM\"] = app_train_domain[\"DAYS_EMPLOYED\"] == 365243\n",
    "# Replace the anomalous values with nan\n",
    "app_train_domain[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "app_test_domain[\"DAYS_EMPLOYED_ANOM\"] = app_test_domain[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test_domain[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "\n",
    "app_train_domain[\"DAYS_EMPLOYED_ANOM\"] = app_train_domain[\"DAYS_EMPLOYED_ANOM\"].astype(\n",
    "    \"int32\"\n",
    ")\n",
    "app_test_domain[\"DAYS_EMPLOYED_ANOM\"] = app_test_domain[\"DAYS_EMPLOYED_ANOM\"].astype(\n",
    "    \"int32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 246)\n",
      "Testing Data Shape:  (48744, 246)\n"
     ]
    }
   ],
   "source": [
    "liste_features, y_train, X_train, X_test, train_ids, test_ids = cleaning(\n",
    "    app_train_domain, app_test_domain, encoding=\"ohe\"\n",
    ")\n",
    "train_final = pd.DataFrame(X_train, columns=liste_features)\n",
    "train_final[\"LABELS\"] = y_train\n",
    "train_final[\"SK_ID_CURR\"] = train_ids\n",
    "\n",
    "test_final = pd.DataFrame(X_test, columns=liste_features)\n",
    "test_final[\"SK_ID_CURR\"] = test_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    \"roc_auc\": make_scorer(roc_auc_score),\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"precision\": make_scorer(precision_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: TARGET\n",
      "0    282686\n",
      "1     24825\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: TARGET\n",
      "1    282686\n",
      "0    282686\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"Original class distribution:\", pd.Series(y_train).value_counts())\n",
    "print(\"Resampled class distribution:\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\",\n",
    "        {\"C\": 10, \"tol\": 0.001, \"random_state\": 42, \"verbose\": 1, \"n_jobs\": -1},\n",
    "        LogisticRegression(),\n",
    "        (X_train, y_train),\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\",\n",
    "        {\"n_estimators\": 100, \"random_state\": 42, \"verbose\": 1, \"n_jobs\": -4},\n",
    "        RandomForestClassifier(),\n",
    "        (X_train, y_train),\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest with SMOTE\",\n",
    "        {\"n_estimators\": 100, \"random_state\": 42, \"verbose\": 1, \"n_jobs\": -4},\n",
    "        RandomForestClassifier(),\n",
    "        (X_train_resampled, y_train_resampled),\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   28.3s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.3s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.4s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.3s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   28.2s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models(models, cv=5, scoring=scoring):\n",
    "    \"\"\"\n",
    "    Evaluate a list of models using cross-validation and store the results in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - models: List of tuples, each containing:\n",
    "        - model_name: Name of the model (str)\n",
    "        - params: Dictionary of parameters for the model\n",
    "        - model: The model instance\n",
    "        - train_data: Tuple containing (X_train, y_train)\n",
    "    - cv: Number of cross-validation folds (int)\n",
    "    - scoring: Scoring metric for cross-validation (str)\n",
    "\n",
    "    Returns:\n",
    "    - cv_results_dict: Dictionary containing cross-validation results for each model\n",
    "    \"\"\"\n",
    "    cv_results_dict = {}\n",
    "\n",
    "    for model_name, params, model, train_data in models:\n",
    "        X_train = train_data[0]\n",
    "        y_train = train_data[1]\n",
    "\n",
    "        cv_results = cross_validate(\n",
    "            model.set_params(**params),\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            return_estimator=True,\n",
    "        )\n",
    "\n",
    "        # Store the results in the dictionary\n",
    "        cv_results_dict[model_name] = cv_results\n",
    "\n",
    "    return cv_results_dict\n",
    "\n",
    "\n",
    "cv_results_dict = evaluate_models(models, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing models:   0%|          | 0/3 [00:00<?, ?it/s]2025/04/08 15:40:49 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Registered model 'Logistic Regression_reg' already exists. Creating a new version of this model...\n",
      "2025/04/08 15:40:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic Regression_reg, version 3\n",
      "Created version '3' of model 'Logistic Regression_reg'.\n",
      "Processing models:  33%|███▎      | 1/3 [00:08<00:16,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: http://localhost:5001/#/experiments/201311528320565050/runs/b2e352dd0a68448c8165dc9540992b78\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/201311528320565050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing models:  33%|███▎      | 1/3 [00:13<00:26, 13.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[138], line 18\u001b[0m\n",
      "\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m element[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# The signature wants the input (X_train) and the output (y_pred)\u001b[39;00m\n",
      "\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# We fit the model so we can use .predict(X_train)\u001b[39;00m\n",
      "\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     19\u001b[0m sample_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "\u001b[1;32m     20\u001b[0m signature \u001b[38;5;241m=\u001b[39m infer_signature(X_train, sample_output, params\u001b[38;5;241m=\u001b[39mparams)\n",
      "\n",
      "File \u001b[0;32m~/Desktop/OC/Projet7/.pixi/envs/default/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m   1387\u001b[0m     )\n",
      "\u001b[1;32m   1388\u001b[0m ):\n",
      "\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Desktop/OC/Projet7/.pixi/envs/default/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[1;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n",
      "\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n",
      "\u001b[1;32m    479\u001b[0m ]\n",
      "\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n",
      "\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n",
      "\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n",
      "\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n",
      "\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n",
      "\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n",
      "\u001b[0;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n",
      "\u001b[1;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "\n",
      "File \u001b[0;32m~/Desktop/OC/Projet7/.pixi/envs/default/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n",
      "\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n",
      "\u001b[1;32m     76\u001b[0m )\n",
      "\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Desktop/OC/Projet7/.pixi/envs/default/lib/python3.13/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n",
      "\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n",
      "\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n",
      "\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n",
      "\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n",
      "\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n",
      "\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "File \u001b[0;32m~/Desktop/OC/Projet7/.pixi/envs/default/lib/python3.13/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "\n",
      "File \u001b[0;32m~/Desktop/OC/Projet7/.pixi/envs/default/lib/python3.13/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n",
      "\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Desktop/OC/Projet7/.pixi/envs/default/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n",
      "\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n",
      "\u001b[0;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n",
      "\u001b[1;32m    198\u001b[0m         X,\n",
      "\u001b[1;32m    199\u001b[0m         y,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n",
      "\u001b[1;32m    203\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/Desktop/OC/Projet7/.pixi/envs/default/lib/python3.13/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n",
      "\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n",
      "\u001b[1;32m    463\u001b[0m         splitter,\n",
      "\u001b[1;32m    464\u001b[0m         min_samples_split,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n",
      "\u001b[1;32m    470\u001b[0m     )\n",
      "\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "mlflow.set_experiment(\"MLflow try2\")\n",
    "# might need to run 'mlflow server --host 127.0.0.1 --port 5001' in the terminal if issues\n",
    "\n",
    "# With tqdm\n",
    "for i, element in enumerate(tqdm(models, desc=\"Processing models\")):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "\n",
    "    # The signature wants the input (X_train) and the output (y_pred)\n",
    "    # We fit the model so we can use .predict(X_train)\n",
    "    model.fit(X_train, y_train)\n",
    "    sample_output = model.predict(X_train)\n",
    "    signature = infer_signature(X_train, sample_output, params=params)\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        if model_name in cv_results_dict:\n",
    "            metrics = cv_results_dict[model_name]\n",
    "            mlflow.log_metrics(  # we take the mean of the metric since we have 5 cv results for each model\n",
    "                {\n",
    "                    \"roc_auc\": metrics.get(\"test_roc_auc\", []).mean(),\n",
    "                    \"accuracy\": metrics.get(\"test_accuracy\", []).mean(),\n",
    "                    \"precision\": metrics.get(\"test_precision\", []).mean(),\n",
    "                    \"recall\": metrics.get(\"test_recall\", []).mean(),\n",
    "                    \"f1\": metrics.get(\"test_f1\", []).mean(),\n",
    "                    \"fit_time\": metrics.get(\"fit_time\", []).mean(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            \"model\",\n",
    "            signature=signature,\n",
    "            registered_model_name=f\"{model_name}_reg\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run loud-mule-333 at: http://localhost:5001/#/experiments/201311528320565050/runs/f3196f2510ae44289112d4b6a9e97887\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/201311528320565050\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
