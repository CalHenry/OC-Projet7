{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction Cleaning Finale\n",
    "def cleaning(features, test_features, encoding=\"ohe\"):\n",
    "    \"\"\"Fonction cleaning finale\"\"\"\n",
    "    # Extract the ids\n",
    "    train_ids = features[\"SK_ID_CURR\"]\n",
    "    test_ids = test_features[\"SK_ID_CURR\"]\n",
    "\n",
    "    # Extract the labels for training\n",
    "    labels = features[\"TARGET\"]\n",
    "\n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns=[\"SK_ID_CURR\", \"TARGET\"])\n",
    "    test_features = test_features.drop(columns=[\"SK_ID_CURR\"])\n",
    "\n",
    "    # One Hot Encoding\n",
    "    if encoding == \"ohe\":\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "\n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join=\"inner\", axis=1)\n",
    "\n",
    "        # No categorical indices to record\n",
    "        cat_indices = \"auto\"\n",
    "\n",
    "    # Integer label encoding\n",
    "    elif encoding == \"le\":\n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "\n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == \"object\":\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(\n",
    "                    np.array(features[col].astype(str)).reshape((-1,))\n",
    "                )\n",
    "                test_features[col] = label_encoder.transform(\n",
    "                    np.array(test_features[col].astype(str)).reshape((-1,))\n",
    "                )\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "\n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "\n",
    "    print(\"Training Data Shape: \", features.shape)\n",
    "    print(\"Testing Data Shape: \", test_features.shape)\n",
    "\n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Impute the domainnomial features\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    features = imputer.fit_transform(features)\n",
    "    test_features = imputer.transform(test_features)\n",
    "\n",
    "    # Scale the domainnomial features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    features = scaler.fit_transform(features)\n",
    "    test_features = scaler.transform(test_features)\n",
    "\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    return feature_names, labels, features, test_features, train_ids, test_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n",
      "Testing data shape:  (48744, 121)\n",
      "3 columns were label encoded.\n",
      "Training Features shape:  (307511, 243)\n",
      "Testing Features shape:  (48744, 239)\n",
      "Training Features shape:  (307511, 240)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-12>:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<positron-console-cell-12>:63: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "\n",
    "# Training data\n",
    "app_train = pd.read_csv(\"../../data/raw/application_train.csv\")\n",
    "print(\"Training data shape: \", app_train.shape)\n",
    "app_train.head(2)\n",
    "\n",
    "# Testing data features\n",
    "app_test = pd.read_csv(\"../../data/raw/application_test.csv\")\n",
    "print(\"Testing data shape: \", app_test.shape)\n",
    "app_test.head(2)\n",
    "\n",
    "# Label Encoding (2 cat√©gories) / One Hot Encoding (n categories)\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == \"object\":\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "\n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "\n",
    "print(\"%d columns were label encoded.\" % le_count)\n",
    "\n",
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "print(\"Training Features shape: \", app_train.shape)\n",
    "print(\"Testing Features shape: \", app_test.shape)\n",
    "\n",
    "\n",
    "# Aligning Training and Testing Data\n",
    "train_labels = app_train[\"TARGET\"]\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join=\"inner\", axis=1)\n",
    "\n",
    "# Add the target back in\n",
    "app_train[\"TARGET\"] = train_labels\n",
    "\n",
    "print(\"Training Features shape: \", app_train.shape)\n",
    "print(\"Testing Features shape: \", app_test.shape)\n",
    "\n",
    "# Create an anomalous flag column\n",
    "app_train[\"DAYS_EMPLOYED_ANOM\"] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app_train[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "\n",
    "app_test[\"DAYS_EMPLOYED_ANOM\"] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "\n",
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()\n",
    "\n",
    "app_train_domain[\"CREDIT_INCOME_PERCENT\"] = (\n",
    "    app_train_domain[\"AMT_CREDIT\"] / app_train_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_train_domain[\"ANNUITY_INCOME_PERCENT\"] = (\n",
    "    app_train_domain[\"AMT_ANNUITY\"] / app_train_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_train_domain[\"CREDIT_TERM\"] = (\n",
    "    app_train_domain[\"AMT_ANNUITY\"] / app_train_domain[\"AMT_CREDIT\"]\n",
    ")\n",
    "app_train_domain[\"DAYS_EMPLOYED_PERCENT\"] = (\n",
    "    app_train_domain[\"DAYS_EMPLOYED\"] / app_train_domain[\"DAYS_BIRTH\"]\n",
    ")\n",
    "\n",
    "app_test_domain[\"CREDIT_INCOME_PERCENT\"] = (\n",
    "    app_test_domain[\"AMT_CREDIT\"] / app_test_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_test_domain[\"ANNUITY_INCOME_PERCENT\"] = (\n",
    "    app_test_domain[\"AMT_ANNUITY\"] / app_test_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_test_domain[\"CREDIT_TERM\"] = (\n",
    "    app_test_domain[\"AMT_ANNUITY\"] / app_test_domain[\"AMT_CREDIT\"]\n",
    ")\n",
    "app_test_domain[\"DAYS_EMPLOYED_PERCENT\"] = (\n",
    "    app_test_domain[\"DAYS_EMPLOYED\"] / app_test_domain[\"DAYS_BIRTH\"]\n",
    ")\n",
    "\n",
    "# Drop the target from the training data\n",
    "if \"TARGET\" in app_train:\n",
    "    train = app_train.drop(columns=[\"TARGET\"])\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "\n",
    "# Feature names\n",
    "features = list(train.columns)\n",
    "\n",
    "# Copy of the testing data\n",
    "test = app_test.copy()\n",
    "\n",
    "\n",
    "# Median imputation of missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Scale each feature to 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train[\"DAYS_EMPLOYED_ANOM\"] = train[\"DAYS_EMPLOYED_ANOM\"].astype(\"int32\")\n",
    "test[\"DAYS_EMPLOYED_ANOM\"] = test[\"DAYS_EMPLOYED_ANOM\"].astype(\"int32\")\n",
    "\n",
    "imputer.fit(train)\n",
    "\n",
    "train_id = train[\"SK_ID_CURR\"]\n",
    "test_id = train[\"SK_ID_CURR\"]\n",
    "\n",
    "# Transform both training and testing data\n",
    "\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(app_test)\n",
    "\n",
    "\n",
    "# Repeat with the scaler\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)\n",
    "train.columns = features\n",
    "test.columns = features\n",
    "\n",
    "train[\"SK_ID_CURR\"] = train_id\n",
    "test[\"SK_ID_CURR\"] = test_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app_train_domain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m app_train_domain[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDAYS_EMPLOYED_ANOM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mapp_train_domain\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDAYS_EMPLOYED_ANOM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\n",
      "\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[1;32m      4\u001b[0m app_test_domain[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDAYS_EMPLOYED_ANOM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m app_test_domain[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDAYS_EMPLOYED_ANOM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\n",
      "\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m app_train_domain\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist():\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'app_train_domain' is not defined"
     ]
    }
   ],
   "source": [
    "app_train_domain[\"DAYS_EMPLOYED_ANOM\"] = app_train_domain[\"DAYS_EMPLOYED_ANOM\"].astype(\n",
    "    \"int32\"\n",
    ")\n",
    "app_test_domain[\"DAYS_EMPLOYED_ANOM\"] = app_test_domain[\"DAYS_EMPLOYED_ANOM\"].astype(\n",
    "    \"int32\"\n",
    ")\n",
    "\n",
    "if \"TARGET\" in app_train_domain.columns.tolist():\n",
    "    app_train_domain = app_train_domain.drop(columns=\"TARGET\")\n",
    "\n",
    "domain_features_names = list(app_train_domain.columns)\n",
    "\n",
    "# Impute the domainnomial features\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "domain_features = imputer.fit_transform(app_train_domain)\n",
    "domain_features_test = imputer.transform(app_test_domain)\n",
    "\n",
    "# Scale the domainnomial features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "domain_features = scaler.fit_transform(domain_features)\n",
    "domain_features_test = scaler.transform(domain_features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_features, labels, train, test, train_ids, test_ids = cleaning(\n",
    "    app_train_domain, app_test_domain\n",
    ")\n",
    "train_final = pd.DataFrame(train, columns=liste_features)\n",
    "train_final[\"LABELS\"] = labels\n",
    "train_final[\"SK_ID_CURR\"] = train_ids\n",
    "\n",
    "test_final = pd.DataFrame(test, columns=liste_features)\n",
    "test_final[\"SK_ID_CURR\"] = test_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n",
      "Testing data shape:  (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv(\"../../data/raw/application_train.csv\")\n",
    "print(\"Training data shape: \", app_train.shape)\n",
    "app_train.head(2)\n",
    "\n",
    "# Testing data features\n",
    "app_test = pd.read_csv(\"../../data/raw/application_test.csv\")\n",
    "print(\"Testing data shape: \", app_test.shape)\n",
    "app_test.head(2)\n",
    "\n",
    "# copy to add fe\n",
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()\n",
    "\n",
    "# feature engineering with domain knowledge variables\n",
    "app_train_domain[\"CREDIT_INCOME_PERCENT\"] = (\n",
    "    app_train_domain[\"AMT_CREDIT\"] / app_train_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_train_domain[\"ANNUITY_INCOME_PERCENT\"] = (\n",
    "    app_train_domain[\"AMT_ANNUITY\"] / app_train_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_train_domain[\"CREDIT_TERM\"] = (\n",
    "    app_train_domain[\"AMT_ANNUITY\"] / app_train_domain[\"AMT_CREDIT\"]\n",
    ")\n",
    "app_train_domain[\"DAYS_EMPLOYED_PERCENT\"] = (\n",
    "    app_train_domain[\"DAYS_EMPLOYED\"] / app_train_domain[\"DAYS_BIRTH\"]\n",
    ")\n",
    "\n",
    "app_test_domain[\"CREDIT_INCOME_PERCENT\"] = (\n",
    "    app_test_domain[\"AMT_CREDIT\"] / app_test_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_test_domain[\"ANNUITY_INCOME_PERCENT\"] = (\n",
    "    app_test_domain[\"AMT_ANNUITY\"] / app_test_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_test_domain[\"CREDIT_TERM\"] = (\n",
    "    app_test_domain[\"AMT_ANNUITY\"] / app_test_domain[\"AMT_CREDIT\"]\n",
    ")\n",
    "app_test_domain[\"DAYS_EMPLOYED_PERCENT\"] = (\n",
    "    app_test_domain[\"DAYS_EMPLOYED\"] / app_test_domain[\"DAYS_BIRTH\"]\n",
    ")\n",
    "\n",
    "# Create an anomalous flag column\n",
    "app_train_domain[\"DAYS_EMPLOYED_ANOM\"] = app_train_domain[\"DAYS_EMPLOYED\"] == 365243\n",
    "# Replace the anomalous values with nan\n",
    "app_train_domain[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "app_test_domain[\"DAYS_EMPLOYED_ANOM\"] = app_test_domain[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test_domain[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "\n",
    "app_train_domain[\"DAYS_EMPLOYED_ANOM\"] = app_train_domain[\"DAYS_EMPLOYED_ANOM\"].astype(\n",
    "    \"int32\"\n",
    ")\n",
    "app_test_domain[\"DAYS_EMPLOYED_ANOM\"] = app_test_domain[\"DAYS_EMPLOYED_ANOM\"].astype(\n",
    "    \"int32\"\n",
    ")\n",
    "\n",
    "# if \"TARGET\" in app_train_domain.columns.tolist():\n",
    "#    app_train_domain = app_train_domain.drop(columns=\"TARGET\")\n",
    "\n",
    "# domain_features_names = list(app_train_domain.columns)\n",
    "\n",
    "# Impute the domainnomial features\n",
    "# imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# domain_features = imputer.fit_transform(app_train_domain)\n",
    "# domain_features_test = imputer.transform(app_test_domain)\n",
    "\n",
    "# Scale the domainnomial features\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# domain_features = scaler.fit_transform(domain_features)\n",
    "# domain_features_test = scaler.transform(domain_features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 246)\n",
      "Testing Data Shape:  (48744, 246)\n"
     ]
    }
   ],
   "source": [
    "liste_features, labels, train, test, train_ids, test_ids = cleaning(\n",
    "    app_train_domain, app_test_domain\n",
    ")\n",
    "train_final = pd.DataFrame(train, columns=liste_features)\n",
    "train_final[\"LABELS\"] = labels\n",
    "train_final[\"SK_ID_CURR\"] = train_ids\n",
    "\n",
    "test_final = pd.DataFrame(test, columns=liste_features)\n",
    "test_final[\"SK_ID_CURR\"] = test_ids\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
