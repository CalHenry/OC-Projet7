{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P7 - Prep the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction Cleaning Finale\n",
    "def cleaning(features, test_features, encoding=\"ohe\"):\n",
    "    \"\"\"Fonction cleaning finale\"\"\"\n",
    "    # Extract the ids\n",
    "    train_ids = features[\"SK_ID_CURR\"]\n",
    "    test_ids = test_features[\"SK_ID_CURR\"]\n",
    "\n",
    "    # Extract the labels for training\n",
    "    labels = features[\"TARGET\"]\n",
    "\n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns=[\"SK_ID_CURR\", \"TARGET\"])\n",
    "    test_features = test_features.drop(columns=[\"SK_ID_CURR\"])\n",
    "\n",
    "    # One Hot Encoding\n",
    "    if encoding == \"ohe\":\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "\n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join=\"inner\", axis=1)\n",
    "\n",
    "        # No categorical indices to record\n",
    "        cat_indices = \"auto\"\n",
    "\n",
    "    # Integer label encoding\n",
    "    elif encoding == \"le\":\n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "\n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == \"object\":\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(\n",
    "                    np.array(features[col].astype(str)).reshape((-1,))\n",
    "                )\n",
    "                test_features[col] = label_encoder.transform(\n",
    "                    np.array(test_features[col].astype(str)).reshape((-1,))\n",
    "                )\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "\n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "\n",
    "    print(\"Training Data Shape: \", features.shape)\n",
    "    print(\"Testing Data Shape: \", test_features.shape)\n",
    "\n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Impute the domainnomial features\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    features = imputer.fit_transform(features)\n",
    "    test_features = imputer.transform(test_features)\n",
    "\n",
    "    # Scale the domainnomial features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    features = scaler.fit_transform(features)\n",
    "    test_features = scaler.transform(test_features)\n",
    "\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    return feature_names, labels, features, test_features, train_ids, test_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n",
      "Testing data shape:  (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv(\"../../data/raw/application_train.csv\")\n",
    "print(\"Training data shape: \", app_train.shape)\n",
    "app_train.head(2)\n",
    "\n",
    "# Testing data features\n",
    "app_test = pd.read_csv(\"../../data/raw/application_test.csv\")\n",
    "print(\"Testing data shape: \", app_test.shape)\n",
    "app_test.head(2)\n",
    "\n",
    "# copy to add fe\n",
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()\n",
    "\n",
    "# feature engineering with domain knowledge variables\n",
    "app_train_domain[\"CREDIT_INCOME_PERCENT\"] = (\n",
    "    app_train_domain[\"AMT_CREDIT\"] / app_train_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_train_domain[\"ANNUITY_INCOME_PERCENT\"] = (\n",
    "    app_train_domain[\"AMT_ANNUITY\"] / app_train_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_train_domain[\"CREDIT_TERM\"] = (\n",
    "    app_train_domain[\"AMT_ANNUITY\"] / app_train_domain[\"AMT_CREDIT\"]\n",
    ")\n",
    "app_train_domain[\"DAYS_EMPLOYED_PERCENT\"] = (\n",
    "    app_train_domain[\"DAYS_EMPLOYED\"] / app_train_domain[\"DAYS_BIRTH\"]\n",
    ")\n",
    "\n",
    "app_test_domain[\"CREDIT_INCOME_PERCENT\"] = (\n",
    "    app_test_domain[\"AMT_CREDIT\"] / app_test_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_test_domain[\"ANNUITY_INCOME_PERCENT\"] = (\n",
    "    app_test_domain[\"AMT_ANNUITY\"] / app_test_domain[\"AMT_INCOME_TOTAL\"]\n",
    ")\n",
    "app_test_domain[\"CREDIT_TERM\"] = (\n",
    "    app_test_domain[\"AMT_ANNUITY\"] / app_test_domain[\"AMT_CREDIT\"]\n",
    ")\n",
    "app_test_domain[\"DAYS_EMPLOYED_PERCENT\"] = (\n",
    "    app_test_domain[\"DAYS_EMPLOYED\"] / app_test_domain[\"DAYS_BIRTH\"]\n",
    ")\n",
    "\n",
    "# Create an anomalous flag column\n",
    "app_train_domain[\"DAYS_EMPLOYED_ANOM\"] = app_train_domain[\"DAYS_EMPLOYED\"] == 365243\n",
    "# Replace the anomalous values with nan\n",
    "app_train_domain[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "app_test_domain[\"DAYS_EMPLOYED_ANOM\"] = app_test_domain[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test_domain[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "\n",
    "app_train_domain[\"DAYS_EMPLOYED_ANOM\"] = app_train_domain[\"DAYS_EMPLOYED_ANOM\"].astype(\n",
    "    \"int32\"\n",
    ")\n",
    "app_test_domain[\"DAYS_EMPLOYED_ANOM\"] = app_test_domain[\"DAYS_EMPLOYED_ANOM\"].astype(\n",
    "    \"int32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"TARGET\" in app_train_domain.columns.tolist():\n",
    "#    app_train_domain = app_train_domain.drop(columns=\"TARGET\")\n",
    "\n",
    "# domain_features_names = list(app_train_domain.columns)\n",
    "\n",
    "# Impute the domainnomial features\n",
    "# imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# domain_features = imputer.fit_transform(app_train_domain)\n",
    "# domain_features_test = imputer.transform(app_test_domain)\n",
    "\n",
    "# Scale the domainnomial features\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# domain_features = scaler.fit_transform(domain_features)\n",
    "# domain_features_test = scaler.transform(domain_features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 246)\n",
      "Testing Data Shape:  (48744, 246)\n"
     ]
    }
   ],
   "source": [
    "liste_features, y_train, X_train, X_test, train_ids, test_ids = cleaning(\n",
    "    app_train_domain, app_test_domain, encoding=\"ohe\"\n",
    ")\n",
    "train_final = pd.DataFrame(X_train, columns=liste_features)\n",
    "train_final[\"LABELS\"] = y_train\n",
    "train_final[\"SK_ID_CURR\"] = train_ids\n",
    "\n",
    "test_final = pd.DataFrame(X_test, columns=liste_features)\n",
    "test_final[\"SK_ID_CURR\"] = test_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    \"roc_auc\": make_scorer(roc_auc_score),\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"precision\": make_scorer(precision_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.50\n",
      "accuracy: 0.92\n",
      "precision: 0.46\n",
      "recall: 0.01\n",
      "f1: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": 10,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": 1,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "logistic_reg = LogisticRegression(**params, tol=0.001)\n",
    "\n",
    "# Use cross_validate with multiple scoring metrics\n",
    "cv_results = cross_validate(\n",
    "    logistic_reg, X_train, y_train, cv=5, scoring=scoring, n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "for metric in scoring.keys():\n",
    "    print(f\"{metric}: {cv_results[f'test_{metric}'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ROC-AUC scores: [0.71384326 0.72469673 0.7041607  0.71798053 0.70832107]\n",
      "Mean ROC-AUC: 0.7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# to remove if cell above is validated\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": 1,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "random_forest_domain = RandomForestClassifier(**params)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    random_forest_domain, X_train, y_train, cv=cv, scoring=\"roc_auc\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc: 0.5005\n",
      "Average accuracy: 0.9193\n",
      "Average precision: 0.6674\n",
      "Average recall: 0.0010\n",
      "Average f1: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": 1,\n",
    "    \"n_jobs\": -4,\n",
    "}\n",
    "\n",
    "random_forest_domain = RandomForestClassifier(**params)\n",
    "\n",
    "# scoring = {\n",
    "#     \"roc_auc\": make_scorer(roc_auc_score),\n",
    "#     \"accuracy\": make_scorer(accuracy_score),\n",
    "#     \"precision\": make_scorer(precision_score),\n",
    "#     \"recall\": make_scorer(recall_score),\n",
    "#     \"f1\": make_scorer(f1_score),\n",
    "# }\n",
    "\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    random_forest_domain,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_estimator=True,\n",
    ")  # cs_results is a dictionnay\n",
    "\n",
    "# Print average scores\n",
    "print(\"\")\n",
    "for metric in [\"roc_auc\", \"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "    print(f\"Average {metric}: {cv_results['test_' + metric].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **good accuracy** but **mediocre recall** (true positive/ true positives + false positives).  \n",
    "THe precision is 0.62 letting us know that the model \n",
    "\n",
    "Our data is imbalanced, thus the model is not capturing the minority class information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: TARGET\n",
      "0    282686\n",
      "1     24825\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: TARGET\n",
      "1    282686\n",
      "0    282686\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"Original class distribution:\", pd.Series(y_train).value_counts())\n",
    "print(\"Resampled class distribution:\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\",\n",
    "        {\"C\": 10, \"tol\": 0.001, \"random_state\": 42, \"verbose\": 1, \"n_jobs\": -1},\n",
    "        LogisticRegression(),\n",
    "        (X_train, y_train),\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\",\n",
    "        {\"n_estimators\": 100, \"random_state\": 42, \"verbose\": 1, \"n_jobs\": -4},\n",
    "        RandomForestClassifier(),\n",
    "        (X_train, y_train),\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest with SMOTE\",\n",
    "        {\"n_estimators\": 100, \"random_state\": 42, \"verbose\": 1, \"n_jobs\": -4},\n",
    "        RandomForestClassifier(),\n",
    "        (X_train_resampled, y_train_resampled),\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   26.9s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.1s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.1s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   29.0s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "cv_results_dict = {}\n",
    "\n",
    "cv = 5\n",
    "\n",
    "for model_name, params, model, train_data in models:\n",
    "    X_train = train_data[0]\n",
    "    y_train = train_data[1]\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        model.set_params(**params),\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_estimator=True,\n",
    "    )  # cs_results is a dictionnay\n",
    "\n",
    "    cv_results_dict[model_name] = cv_results\n",
    "    # model.set_params(**params)\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    # reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   11.8s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.6s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.7s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.6s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.4s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   27.1s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models(models, cv=5, scoring=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Evaluate a list of models using cross-validation and store the results in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - models: List of tuples, each containing:\n",
    "        - model_name: Name of the model (str)\n",
    "        - params: Dictionary of parameters for the model\n",
    "        - model: The model instance\n",
    "        - train_data: Tuple containing (X_train, y_train)\n",
    "    - cv: Number of cross-validation folds (int)\n",
    "    - scoring: Scoring metric for cross-validation (str)\n",
    "\n",
    "    Returns:\n",
    "    - cv_results_dict: Dictionary containing cross-validation results for each model\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store results\n",
    "    cv_results_dict = {}\n",
    "\n",
    "    for model_name, params, model, train_data in models:\n",
    "        X_train = train_data[0]\n",
    "        y_train = train_data[1]\n",
    "\n",
    "        cv_results = cross_validate(\n",
    "            model.set_params(**params),\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            return_estimator=True,\n",
    "        )\n",
    "\n",
    "        # Store the results in the dictionary\n",
    "        cv_results_dict[model_name] = cv_results\n",
    "\n",
    "    return cv_results_dict\n",
    "\n",
    "\n",
    "cv_results_dict = {}\n",
    "cv_results_dict = evaluate_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  36 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-4)]: Done 100 out of 100 | elapsed:   17.4s finished\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "2025/04/07 16:04:38 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "Registered model 'tracking-quickstart' already exists. Creating a new version of this model...\n",
      "2025/04/07 16:05:54 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: tracking-quickstart, version 5\n",
      "Created version '5' of model 'tracking-quickstart'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run clumsy-koi-940 at: http://127.0.0.1:5000/#/experiments/726532937351277124/runs/2e70af58225c446989fa861ada3fd324\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/726532937351277124\n"
     ]
    }
   ],
   "source": [
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow try1\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log each metric individually\n",
    "    mlflow.log_metric(\"accuracy\", cv_results[\"test_accuracy\"].mean())\n",
    "    mlflow.log_metric(\"precision\", cv_results[\"test_precision\"].mean())\n",
    "    mlflow.log_metric(\"recall\", cv_results[\"test_recall\"].mean())\n",
    "    mlflow.log_metric(\"f1\", cv_results[\"test_f1\"].mean())\n",
    "\n",
    "    # Log the loss metric\n",
    "    # mlflow.log_metric(\n",
    "    #     {\n",
    "    #         #\"roc_auc_score\": cv_results[\"test_roc_auc\"],\n",
    "    #         \"accuracy\": (cv_results[\"test_accuracy\"].mean()),\n",
    "    #         \"precision\": (cv_results[\"test_precision\"].mean()),\n",
    "    #         \"recall\": (cv_results[\"test_recall\"].mean()),\n",
    "    #         \"f1\": (cv_results[\"test_f1\"].mean()),\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"RandomForest for credit classification\")\n",
    "\n",
    "    random_forest_domain.fit(X_train, y_train)\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, random_forest_domain.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=random_forest_domain,\n",
    "        artifact_path=\"credit_model_test1\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"tracking-quickstart\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
